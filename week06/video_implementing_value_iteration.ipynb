{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_v2vs4UUcXv"
      },
      "source": [
        "# Video: Implementing Value Iteration\n",
        "\n",
        "Value iteration is our first algorithm for computing optimal values for Markov decision processes with infinite horizons.\n",
        "This video implements data structures to represent a finite Markov decision process and compute its optimal values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvRpBPsASA5l"
      },
      "source": [
        "Script:\n",
        "* Value iteration is a simple algorithm for computing optimal values for Markov decision processes.\n",
        "* It works for finite Markov decision processes and converges to the infinite horizon values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uf2T8xtuQv0V"
      },
      "source": [
        "## Problem Setup\n",
        "\n",
        "Problem size:\n",
        "* $k$ actions\n",
        "* $n$ states\n",
        "\n",
        "Problem dynamics:\n",
        "* $\\mathcal{R}: k \\times n$ array of expected rewards for each action+state\n",
        "* $\\mathcal{P}: k \\times n \\times n$ array of transition probabilities for each action/current state/next state.\n",
        "* $\\gamma$ discount factor for future rewards"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxmCt7d3SCnJ"
      },
      "source": [
        "Script:\n",
        "* We will describe the problem using $k$ actions and $n$ states.\n",
        "* The rewards will be in a 2-dimensional array $\\mathcal{R}$ with shape $k$ by $n$.\n",
        "* The rows of $\\mathcal{R}$ will identify actions, the columns of $\\mathcal{r}$ will identify states, and the values in $\\mathcal{R}$ will be the expected rewards.\n",
        "* The transition probabilities will be in a 3-dimensional array $\\mathcal{P}$ where the first dimension identifies an action, the second dimension identifies the current state, and third dimension identifies the next state.\n",
        "* Finally, the parameter $\\gamma$ will be the discount factor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jevp1z8zRel3"
      },
      "source": [
        "## Value Iteration Algorithm\n",
        "\n",
        "1. Initialize $\\mathbf{v}_0 = [0,\\ldots, 0]$.\n",
        "2. Repeat until values stop changing significantly:\n",
        "\\begin{array}{rcl}\n",
        "\\mathbf{v}_{i+1}&=&\\max_a \\mathcal{R}^a + \\gamma \\mathcal{P}^a \\mathbf{v}_i\n",
        "\\end{array}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHWfQHnYSIwo"
      },
      "source": [
        "Script:\n",
        "* Value iteration typically starts with a vector of all zero values.\n",
        "* This initialization will lead to the $i$th value vector corresponding to the best possible value achievable within $i$ steps.\n",
        "* In the update formula, $\\mathcal{R}^a$ denotes the average state rewards after picking action $a$ while $\\mathcal{P}^a$ similarly denotes the transition probabilities after picking action $a$.\n",
        "* Then given the $i$th vector of values, the next vector of values is computed for each possible first action $a$, using $\\gamma$, $\\mathcal{R}^a$ and $\\mathcal{P}^a$ to compute the immediate reward and the discounted future reward.\n",
        "* This process continues as long as the values keep changing by meaningful amounts.\n",
        "* Specific thresholds for meaningful will depend on the particular problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBLoCvelQDIz"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PdVlgHBiPt-t"
      },
      "outputs": [],
      "source": [
        "# one step state-action values from a value estimate.\n",
        "# will use this a lot!\n",
        "\n",
        "def compute_qT_once(R, P, gamma, v):\n",
        "    return R + gamma * P @ v"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yD3yCQI-ST4p"
      },
      "source": [
        "Script:\n",
        "* This function, `compute_qT_once`, will compute the inner expression of the value update for all actions at once.\n",
        "* It will return an array with a value for every pair of state and action.\n",
        "* It is named after the $q$ function for state and action values, but transposed since the array is indexed by action first and then state.\n",
        "* You will see this function and the next repeated in later videos about different value and policy iteration algorithms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XzYY-lDXQcIC"
      },
      "outputs": [],
      "source": [
        "def iterate_values_once(R, P, gamma, v):\n",
        "    return np.max(compute_qT_once(R, P, gamma, v), axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3__SOtESWIA"
      },
      "source": [
        "Script:\n",
        "* This function will compute the new values for one pass through the loop.\n",
        "* All it does is compute the transposed $q$ values and then take the maximum value by action for each state.\n",
        "* So the result has a value for each state based on one optimal choice based on the previously computed values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mp4onuTaScAf"
      },
      "outputs": [],
      "source": [
        "def value_iteration(R, P, gamma, max_iterations=100, tolerance=0.001):\n",
        "    # initial approximation v_0\n",
        "    v_old = np.zeros(R.shape[-1])\n",
        "\n",
        "    for i in range(max_iterations):\n",
        "        # compute v_{i+1}\n",
        "        v_new = iterate_values_once(R, P, gamma, v_old)\n",
        "\n",
        "        # check if values did not change much\n",
        "        if np.max(np.abs(v_new - v_old)) < tolerance:\n",
        "            return v_new\n",
        "\n",
        "        v_old = v_new\n",
        "\n",
        "    # return v_{max_iterations}\n",
        "    return v_old"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdVfiU67SjbI"
      },
      "source": [
        "Script:\n",
        "* Now we can write the whole value iteration function.\n",
        "* I added two extra parameters for the maximum number of iterations and a default numerical tolerance.\n",
        "* Both parameters are used to guarantee that value iteration stops in a timely manner.\n",
        "* The function just consists of initializing the values to zero, and repeatedly iterating on the values until either the maximum number of iterations were made or the largest value change between updates was below the tolerance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHN4QBgITSyI"
      },
      "source": [
        "## Example Environment\n",
        "\n",
        "<table>\n",
        "<tr><td align=\"right\">0\ud83e\uddca</td><td align=\"right\">1\ud83e\uddca</td><td align=\"right\">2\ud83e\uddca</td><td align=\"right\">3\ud83e\uddca</td><td align=\"right\">4\ud83e\uddca</td><td align=\"right\">5\ud83e\uddca</td><td align=\"right\">6\ud83e\uddca</td></tr>\n",
        "<tr><td align=\"right\">7\ud83e\uddca</td><td align=\"right\">8\ud83e\uddca</td><td align=\"right\">9\ud83e\uddca</td><td align=\"right\">10\ud83e\uddca</td><td align=\"right\">11\ud83e\uddca</td><td align=\"right\">12\ud83e\uddca</td><td align=\"right\">13\ud83e\uddca</td></tr>\n",
        "<tr><td align=\"right\">14\ud83e\uddca</td><td align=\"right\">15\ud83e\uddca</td><td align=\"right\">16\ud83e\uddca</td><td align=\"right\">17\ud83e\uddca</td><td align=\"right\">18\ud83e\uddca</td><td align=\"right\">19\ud83e\uddca</td><td align=\"right\">20\ud83e\uddca</td></tr>\n",
        "<tr><td align=\"right\">21\ud83e\uddca</td><td align=\"right\">22\ud83e\uddca</td><td align=\"right\">23\ud83e\uddca</td><td align=\"right\">24\ud83e\uddca</td><td align=\"right\">25\ud83e\uddca</td><td align=\"right\">26\ud83e\uddca</td><td align=\"right\">27\ud83e\uddca</td></tr>\n",
        "<tr><td align=\"right\">28\ud83e\uddca</td><td align=\"right\">29\ud83e\uddca</td><td align=\"right\">30\ud83e\uddca</td><td align=\"right\">31\ud83e\uddca</td><td align=\"right\">32\ud83e\uddca</td><td align=\"right\">33\ud83e\uddca</td><td align=\"right\">34\ud83e\uddca</td></tr>\n",
        "<tr><td align=\"right\">35\ud83e\uddca</td><td align=\"right\">36\ud83e\uddca</td><td align=\"right\">37\ud83e\uddca</td><td align=\"right\">38\ud83e\uddca</td><td align=\"right\">39\ud83e\uddca</td><td align=\"right\">40\ud83e\uddca</td><td align=\"right\">41\ud83e\uddca</td></tr>\n",
        "<tr><td align=\"right\">42\ud83e\uddca</td><td align=\"right\">43\ud83e\uddca</td><td align=\"right\">44\ud83e\uddca</td><td>45\ud83e\uddca</td><td align=\"right\">46\ud83e\uddca</td><td align=\"right\">47\ud83e\uddca</td><td align=\"right\">48\ud83d\udc1f</td></tr>\n",
        "<tr><td></td></tr>\n",
        "<tr><td align=\"right\">49\u2611\ufe0f</td></tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVUwBxBLTXiq"
      },
      "source": [
        "Script:\n",
        "* Here is an example environment for a penguin agent to navigate.\n",
        "* States 0-48 form a grid to navigate while state 49 is a terminal state.\n",
        "* State 48 has a fish for the penguin and has reward 1.\n",
        "* From that state, all transitions are to the done state 49 where the penguin stops.\n",
        "* All the other states allow horizontal and vertical movement within the grid.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5f1gNjaSl2o"
      },
      "outputs": [],
      "source": [
        "actions = [\"\u2b06\ufe0f\", \"\u2b07\ufe0f\", \"\u2b05\ufe0f\", \"\u27a1\ufe0f\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyKVgbvWS3Rc"
      },
      "source": [
        "Script:\n",
        "* The actions in this environment will just be moving the penguin up, down, left or right within the grid.\n",
        "* If the action would move off the grid, the penguin will stay in the same position.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5iDaPFpTPY8"
      },
      "outputs": [],
      "source": [
        "P = np.zeros(shape=(len(actions), 50, 50))\n",
        "for s in range(48):\n",
        "    # row major order with (0,0) as top left\n",
        "    x = s % 7\n",
        "    y = s // 7\n",
        "\n",
        "    # up action\n",
        "    if y > 0:\n",
        "        P[0, s, s-7] = 1\n",
        "    else:\n",
        "        P[0, s, s] = 1\n",
        "\n",
        "    # down action\n",
        "    if y < 6:\n",
        "        P[1, s, s+7] = 1\n",
        "    else:\n",
        "        P[1, s, s] = 1\n",
        "\n",
        "    # left action\n",
        "    if x > 0:\n",
        "        P[2, s, s-1] = 1\n",
        "    else:\n",
        "        P[2, s, s] = 1\n",
        "\n",
        "    # right action\n",
        "    if x < 6:\n",
        "        P[3, s, s+1] = 1\n",
        "    else:\n",
        "        P[3, s, s] = 1\n",
        "\n",
        "# fish state goes to terminal state\n",
        "P[:,48,49] = 1\n",
        "\n",
        "# stay in terminal state\n",
        "P[:,49,49] = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4nMR5oGTdBW"
      },
      "source": [
        "## Example Environment Rewards\n",
        "\n",
        "<table>\n",
        "<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
        "<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
        "<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
        "<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
        "<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
        "<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>\n",
        "<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td></tr>\n",
        "<tr><td></td></tr>\n",
        "<tr><td>0</td></tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3coYCxqTgN8"
      },
      "source": [
        "Script:\n",
        "* Here are the rewards for each state.\n",
        "* They do not depend on the actions.\n",
        "* There is a reward of one for the fish state and all the other rewards are zero."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWss_XI9Tq7w",
        "outputId": "ba3fb3ba-ffa7-47ae-c4ea-92d7b3ac73fb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        1., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        1., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        1., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        1., 0.]])"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "R = np.zeros(shape=(4,50))\n",
        "R[:,48] = 1\n",
        "R"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOn-U_kSTv6w"
      },
      "source": [
        "Script:\n",
        "* Here is the R array representing the rewards for this environment.\n",
        "* This is pretty simple to setup since only one state has non-zero rewards.\n",
        "* Let's plot where those values are just to spot check."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        },
        "id": "fW1Q5g9aVG69",
        "outputId": "d7a8e593-b282-4a02-d863-23be9c2d4014"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 4 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "for a in range(4):\n",
        "    plt.subplot(1, 4, a + 1)\n",
        "    plt.imshow(R[a,:49].reshape(7, 7));\n",
        "\n",
        "plt.subplots_adjust(wspace=0.5)\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_O18-RMWYW4"
      },
      "source": [
        "Script:\n",
        "* I left out the terminal state.\n",
        "* Each action just has a reward when you get to the bottom left where the fish is."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkR-cvViTpUX",
        "outputId": "6b4c262c-3e92-49b2-8ab3-eacfa5b52409"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.28242954, 0.3138106 , 0.34867844, 0.38742049, 0.43046721,\n",
              "       0.4782969 , 0.531441  , 0.3138106 , 0.34867844, 0.38742049,\n",
              "       0.43046721, 0.4782969 , 0.531441  , 0.59049   , 0.34867844,\n",
              "       0.38742049, 0.43046721, 0.4782969 , 0.531441  , 0.59049   ,\n",
              "       0.6561    , 0.38742049, 0.43046721, 0.4782969 , 0.531441  ,\n",
              "       0.59049   , 0.6561    , 0.729     , 0.43046721, 0.4782969 ,\n",
              "       0.531441  , 0.59049   , 0.6561    , 0.729     , 0.81      ,\n",
              "       0.4782969 , 0.531441  , 0.59049   , 0.6561    , 0.729     ,\n",
              "       0.81      , 0.9       , 0.531441  , 0.59049   , 0.6561    ,\n",
              "       0.729     , 0.81      , 0.9       , 1.        , 0.        ])"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gamma=0.9\n",
        "v_star = value_iteration(R, P, gamma)\n",
        "v_star"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xb-e0xXRTnc7"
      },
      "source": [
        "Script:\n",
        "* Now we can just call the `value_iteration` function that we wrote earlier.\n",
        "* You can see the zero value for the last state, the terminal state, since it is after the fish reward.\n",
        "* Just before it, you can see the reward of one for getting to the fish.\n",
        "* You can also see powers of 0.9 for the other states, but it is a little hard to follow.\n",
        "* Let's plot that like the rewards."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "AsqWlCoqT2QN",
        "outputId": "b3fc8f6a-ecc5-4173-98df-d27242d6d444"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.imshow(v_star[:49].reshape(7, 7));"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOoenr_pTzMq"
      },
      "source": [
        "Script:\n",
        "* With this chart, you can see that the reward is based on the number of steps the penguin needs to get to the fish."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdnAz0I4T-c7"
      },
      "source": [
        "Script: (faculty on screen)\n",
        "* Value iteration is an easy to implement method for computing optimal values.\n",
        "* We will use variations on this algorithm for policy iteration methods which also return optimal actions."
      ]
    }
  ],
  "metadata": {
    "colab": {},
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}