{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYMHII4woS_B"
      },
      "source": [
        "# Video: Visualizing Text as Tokens\n",
        "\n",
        "One key step in the evolution of large language models was transitioning to predicting tokens instead of just bytes.\n",
        "This video how the compression method byte pair encoding was repurposed to identify frequent text patterns for token selection, and gives examples of the increased semantic information of the resulting tokens."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-TNsOUpLHtS"
      },
      "source": [
        "Script:\n",
        "* One step in the development of large language models was a transition from predicting bytes or words.\n",
        "* Early models predicted one byte at a time, so any text could be modeled, but many predictions were needed to output a whole word.\n",
        "* Later models predicted whole words which required fewer predictions and anecdotally helped coherency, but had trouble when new words appear.\n",
        "* Just this month, the Oxford English dictionary added the word \"agritech\" meaning \"Technology that is used in agriculture to increase yield, efficiency, productivity, sustainability\".\n",
        "* You and I could guess the meaning of that word from the prefix \"agri\" and suffix \"tech\".\n",
        "* Tokens allow a language model to work with bigger common pieces of text while maintaining the flexibility of predicting individual bytes when something new is encountered.\n",
        "* For example, \"agri\" and \"tech\" might both be tokens, and the language model could infer a likely meaning based on the known usage of those tokens separate from each other.\n",
        "* Let's look at the tokens of a real large language model now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nvQzmmf7nd5s"
      },
      "outputs": [],
      "source": [
        "import tiktoken"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQWEJa-HIdLC"
      },
      "source": [
        "Script:\n",
        "* I am going to use this module tiktoken by OpenAI for tokenization.\n",
        "* OpenAI uses this module for fast tokenization in their production language models and apps like ChatGPT."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gbACGuzLLOO4"
      },
      "outputs": [],
      "source": [
        "test_string = \"The quick brown fox jumps over the lazy dog\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcabwTegIuxb"
      },
      "source": [
        "Script:\n",
        "* For initial tests, I will use the common typing test sentence \"The quick brown fox jumps over the lazy dog\".\n",
        "* If you aren't familiar with this sentence, it was written with each of the 26 letters of the English alphabet.\n",
        "* Early language models would just break it up into bytes or characters.\n",
        "* Here are the characters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyAP1ABsLSHQ",
        "outputId": "78d8e9da-2aa6-48fa-a5e0-68e610740329"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['T',\n",
              " 'h',\n",
              " 'e',\n",
              " ' ',\n",
              " 'q',\n",
              " 'u',\n",
              " 'i',\n",
              " 'c',\n",
              " 'k',\n",
              " ' ',\n",
              " 'b',\n",
              " 'r',\n",
              " 'o',\n",
              " 'w',\n",
              " 'n',\n",
              " ' ',\n",
              " 'f',\n",
              " 'o',\n",
              " 'x',\n",
              " ' ',\n",
              " 'j',\n",
              " 'u',\n",
              " 'm',\n",
              " 'p',\n",
              " 's',\n",
              " ' ',\n",
              " 'o',\n",
              " 'v',\n",
              " 'e',\n",
              " 'r',\n",
              " ' ',\n",
              " 't',\n",
              " 'h',\n",
              " 'e',\n",
              " ' ',\n",
              " 'l',\n",
              " 'a',\n",
              " 'z',\n",
              " 'y',\n",
              " ' ',\n",
              " 'd',\n",
              " 'o',\n",
              " 'g']"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "[c for c in test_string]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhGYjgIHJasu"
      },
      "source": [
        "Script:\n",
        "* From an English-centered viewpoint, characters and bytes used to look the same, but many languages use an extended character set where they are different.\n",
        "* Let's look at the bytes now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOsf6zt7LayC",
        "outputId": "506f1773-2f10-4884-a05f-52896f121ba8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "b'The quick brown fox jumps over the lazy dog'"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_string_bytes = test_string.encode(\"utf-8\")\n",
        "test_string_bytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Jzl5Ry7LroO",
        "outputId": "decfafb0-e82d-458c-8a38-a2c9f0115d1b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[84,\n",
              " 104,\n",
              " 101,\n",
              " 32,\n",
              " 113,\n",
              " 117,\n",
              " 105,\n",
              " 99,\n",
              " 107,\n",
              " 32,\n",
              " 98,\n",
              " 114,\n",
              " 111,\n",
              " 119,\n",
              " 110,\n",
              " 32,\n",
              " 102,\n",
              " 111,\n",
              " 120,\n",
              " 32,\n",
              " 106,\n",
              " 117,\n",
              " 109,\n",
              " 112,\n",
              " 115,\n",
              " 32,\n",
              " 111,\n",
              " 118,\n",
              " 101,\n",
              " 114,\n",
              " 32,\n",
              " 116,\n",
              " 104,\n",
              " 101,\n",
              " 32,\n",
              " 108,\n",
              " 97,\n",
              " 122,\n",
              " 121,\n",
              " 32,\n",
              " 100,\n",
              " 111,\n",
              " 103]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "[b for b in test_string_bytes]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oj4y2bl4Jqi8"
      },
      "source": [
        "Script:\n",
        "* Each of those bytes has 256 possibilities.\n",
        "* Only a few characters can be encoded that way.\n",
        "* Chinese will not fit, and emojis will not fit either."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OjlrB7pxLd8E"
      },
      "outputs": [],
      "source": [
        "test_emoji = '\ud83e\udd8a'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "180PaBuwJ_8H"
      },
      "source": [
        "Script:\n",
        "* Here is the emoji for a fox."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t74JfsQZLzby",
        "outputId": "7b05ea83-d071-4a47-8f00-a541970e17f1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "b'\\xf0\\x9f\\xa6\\x8a'"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_emoji_bytes = test_emoji.encode(\"utf-8\")\n",
        "test_emoji_bytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1JbDEE1L2Xs",
        "outputId": "4b7d75d2-c729-460f-cee5-364d5a3d8571"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[240, 159, 166, 138]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "[b for b in test_emoji_bytes]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0odzV78YKFVy"
      },
      "source": [
        "Script:\n",
        "* Unlike the previous sentence where each character mapped to one byte, the fox emoji is encoded by 4 bytes.\n",
        "* The early language models would need 4 correct predictions to produce a fox emoji.\n",
        "* Let's look at the tokens now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "63g83BnXnvAI"
      },
      "outputs": [],
      "source": [
        "encoder = tiktoken.encoding_for_model(\"gpt-4o\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27rEcYXlKS5U"
      },
      "source": [
        "Script:\n",
        "* This is the token encoder used by the GPT-4o model released in May 2024.\n",
        "* One of the advertised features of this model was increased tokenization of Asian languages to make their speed and text quality better."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpyUY4NPnz83",
        "outputId": "48b706cb-f4b5-4cd3-c4e0-ca1154703030"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[976, 4853, 19705, 68347, 65613, 1072, 290, 29082, 6446]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "token_ids = encoder.encode(test_string)\n",
        "token_ids"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9E8jgtUVKqkK"
      },
      "source": [
        "Script:\n",
        "* Here is the encoding of our test sentence from before.\n",
        "* Each number identifies a single token, and some of these numbers are much higher than the 256 values used for just bytes.\n",
        "* What do these token identifiers mean?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snHLW3kTn_EK",
        "outputId": "f0ae02c3-7d49-4ad5-d44e-60ee9dcbe1bf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['The', ' quick', ' brown', ' fox', ' jumps', ' over', ' the', ' lazy', ' dog']"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokens = [encoder.decode([token_id]) for token_id in token_ids]\n",
        "tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SN4msQuzLCJo"
      },
      "source": [
        "Script:\n",
        "* These tokens roughly correspond to words.\n",
        "* But note that they also include the spaces for each word.\n",
        "* So most of these tokens have the effect of ending the previous word and starting a new word.\n",
        "* They do not necessarily encode whole words though.\n",
        "* A token starting with L Y space could come after the token for space quick to produce the word quickly.\n",
        "* Let's look at the tokenization of the fox emoji."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KL2rdxqpMCCf",
        "outputId": "996acf9b-fe73-46d2-ff40-0734891a6d15"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['\ufffd', '\ufffd', '\ufffd']"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "[encoder.decode([token_id]) for token_id in encoder.encode(test_emoji)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4WtQGAyLdqi"
      },
      "source": [
        "Script:\n",
        "* The tokenization of the fox emoji is less comprehensible.\n",
        "* There are only 3 tokens where the emoji was previously encoded with 4 bytes.\n",
        "* So 2 of those bytes must have been common and combined into a token for a slight savings.\n",
        "* This suggests that the fox emoji is not common enough in the training data set to be assigned a dedicated token.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "kPJ1VE9pMSn1",
        "outputId": "50b7ad36-cfd7-45c8-9728-a1a7d76de776"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\ud83e\udd8a'"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "encoder.decode(encoder.encode(test_emoji))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmlgTdDiMpAu"
      },
      "source": [
        "Script:\n",
        "* Despite that missing data coverage, the fox emoji can still be produced from these tokens."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2a9DjwnLG5p"
      },
      "source": [
        "Script: (faculty on screen)\n",
        "* Tokenization was a very interesting development for language models.\n",
        "* Tokens are simultaneously a coverage improvement, efficiency improvement, and quality improvement for language models.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {},
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}